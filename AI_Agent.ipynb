{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMP26EufloPuddKsZPY7bzP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yazeedx0/AI-Agent/blob/main/AI_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPnFO2y5yY1b"
      },
      "outputs": [],
      "source": [
        "!pip install -qU crewai[tools,agentops]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU tavily-python scrapegraph-py"
      ],
      "metadata": {
        "id": "Wp95q_48FzQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "from crewai.tools import tool\n",
        "import agentops\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from google.colab import userdata\n",
        "from tavily import TavilyClient\n",
        "from scrapegraph_py import Client\n",
        "import os\n",
        "import json\n"
      ],
      "metadata": {
        "id": "ZLuSL_WXyvhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"open-ai\")\n",
        "os.environ [\"AGENTOPS_API_KEY\"] = userdata.get(\"Agentops\")\n",
        "agentops.init(\n",
        "    api_key=userdata.get('Agentops'),\n",
        "    skip_auto_end_session=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtuczB9j0of-",
        "outputId": "2caaa3bc-ffee-448b-aad3-757dacdea049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ðŸ–‡ AgentOps: API Key is invalid: {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}.\n",
            "\t    Find your API key at https://app.agentops.ai/settings/projects\n",
            "ðŸ–‡ AgentOps: API Key is invalid: {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}.\n",
            "\t    Find your API key at https://app.agentops.ai/settings/projects\n",
            "ðŸ–‡ AgentOps: AgentOps has already been initialized. If you are trying to start a session, call agentops.start_session() instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aieqmlEUMOIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import search\n",
        "import time\n",
        "from genericpath import exists\n",
        "output_dir = \"./ai-agent-output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "basic_llm=LLM(model=\"gpt-4o-mini\", temperature=0)\n",
        "search_client = TavilyClient(api_key=userdata.get('tavily'))\n",
        "scrape_client=Client(api_key=\"sgai-de5b1ded-7a95-4933-8754-9eaf166e6895\")"
      ],
      "metadata": {
        "id": "iRzYLg0r2U6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Agent A**"
      ],
      "metadata": {
        "id": "v2WpoBHO3Y6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "no_keywords = 5\n",
        "class SuggestedSearchQueries(BaseModel):\n",
        "    queries: List[str] = Field(\n",
        "        ...,\n",
        "        title=\"Suggested search queries to be passed to the search engine\",\n",
        "        min_items=1,\n",
        "        max_items=no_keywords\n",
        "    )\n",
        "\n",
        "search_queries_recommendation_agent = Agent(\n",
        "    role=\"Search Queries Recommendation Agent\",\n",
        "    goal=\"\\n\".join([\n",
        "        \"The agent is designed to generate a diverse list of suggested search queries to be submitted to the search engine.\",\n",
        "        \"These queries should focus on locating specific products efficiently and effectively.\"\n",
        "    ]),\n",
        "    backstory=\"The agent specializes in assisting product searches by providing tailored and optimized search query suggestions.\",\n",
        "    llm=basic_llm,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "search_queries_recommendation_task = Task(\n",
        "    description=\"\\n\".join([\n",
        "        \"Yazeed is tasked with identifying and purchasing a {product_name} at the most competitive price.\",\n",
        "        \"The term 'best price' reflects the concept of 'value for strategy,' ensuring that the chosen product aligns with the company's strategic goals and delivers the highest return on investment.\",\n",
        "        \"The target websites for purchasing include: {websites_list}.\",\n",
        "        \"The objective is to identify all available products online for comprehensive comparison in a subsequent phase.\",\n",
        "        f\"The selected stores must offer products within {{country_name}}.\",\n",
        "        f\"Generate a maximum of {no_keywords} search queries.\",\n",
        "        \"The Search keywords in {language}\",\n",
        "        \"Each search query must lead to an e-commerce product page rather than blogs or generic listing pages.\"\n",
        "    ]),\n",
        "    expected_output=\"A JSON object containing a list of suggested search queries.\",\n",
        "    output_json=SuggestedSearchQueries,\n",
        "    output_file=os.path.join(output_dir, \"Step_1_Suggested_search_queries.json\"),\n",
        "    agent=search_queries_recommendation_agent\n",
        ")\n",
        "\n",
        "print(\"Task successfully defined!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOEHFG2OAOMO",
        "outputId": "6682c09c-efbc-400f-b4de-720d705cf5ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task successfully defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Agent B**"
      ],
      "metadata": {
        "id": "4RK1q_6hG11-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleSearchResult(BaseModel):\n",
        "  title:str\n",
        "  url:str = Field(..., title=\"the page url\")\n",
        "  content:str\n",
        "  score:float\n",
        "  search_query:str\n",
        "\n",
        "\n",
        "class ALLSearchResults(BaseModel):\n",
        "  results: List[SingleSearchResult]\n",
        "@tool\n",
        "def search_engine_tool(query: str):\n",
        "  \"\"\"Usful for search-based queries. use this to find current information about any query related page using a search engine\"\"\"\n",
        "\n",
        "  return search_client.search(query)\n",
        "\n",
        "search_angine_agent = Agent(\n",
        "    role= \"Search Engine Agent\",\n",
        "    goal= \"To Search for poducts based on the suggested queris\",\n",
        "    backstory = \"The agent specializes in assisting product searches by providing tailored and optimized search query suggestions\",\n",
        "    llm = basic_llm,\n",
        "    verbose=True,\n",
        "    tools=[search_engine_tool]\n",
        ")\n",
        "\n",
        "search_engine_taks = Task(\n",
        "    description=\"\\n\".join([\"The task is to search for product based on the suggested search queries\",\n",
        "    \"You have to collect results from multiple search queries\",\n",
        "    \"Ignore any susbicious links or not an ecommerce website link.\",\n",
        "    \"Ignore any search results with confidence score less than ({score_th}).\",\n",
        "    \"The search results will be used to compare prices of products form different websites\",\n",
        "\n",
        "\n",
        "    ]),\n",
        "    expected_output=\"A JSON Object containing the search resutls\",\n",
        "    output_jsont=ALLSearchResults,\n",
        "    ouput_file=os.path.join(output_dir,\"Step_2_search_results.json\"),\n",
        "    agent= search_angine_agent\n",
        "\n",
        ")\n",
        "print(\"Task successfully defined!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw5_cLt9G5Rk",
        "outputId": "15c52156-79ca-425b-ae06-8ae6671ac379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task successfully defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Agent C**"
      ],
      "metadata": {
        "id": "Cj4gD5zwQxfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProductSpecification(BaseModel):\n",
        "    specification_name: str = Field(..., title=\"Name of the specification\")\n",
        "    specification_value: str = Field(..., title=\"Value of the specification\")\n",
        "\n",
        "class SingleExtractProduct(BaseModel):\n",
        "    page_url: str = Field(..., title=\"The original URL of the product page\")\n",
        "    product_title: str = Field(..., title=\"Title of the product\")\n",
        "    product_url: str = Field(..., title=\"URL of the product\")\n",
        "    product_image_url: str = Field(..., title=\"URL of the product image\")\n",
        "    product_current_price: float = Field(..., title=\"Current price of the product\")\n",
        "    product_original_price: float = Field(..., title=\"Original price of the product\")\n",
        "    product_discount_percentage: str = Field(..., title=\"Discount percentage of the product\")\n",
        "    product_specs: List[ProductSpecification] = Field(..., title=\"List of product specifications\")\n",
        "    agent_recommendation_rank: int = Field(..., title=\"Recommendation rank given by the agent\")\n",
        "    agent_recommendation_notes: str = Field(..., title=\"Notes for the agent's recommendation\")\n",
        "\n",
        "class AllExtractProducts(BaseModel):\n",
        "    products: List[SingleExtractProduct] = Field(..., title=\"List of all extracted products\")\n",
        "@tool\n",
        "def web_scraping_tool(page_url: str, required_fields: list):\n",
        "  \"\"\" An AI Tool to help an agent to scrape a web page\n",
        "  Example:\n",
        "   web_scraping_tool(\n",
        "    page_url=\"\",\n",
        "    required_fields=[\"product_title\", \"current_price\",\"old_price\"]\n",
        "   )\n",
        "   \"\"\"\n",
        "  details = scrape_client.smartscraper(\n",
        "      website_url=page_url,\n",
        "      user_prompt=\"Extract \" + json.dumps(required_fields, ensure_ascii=False) + \" From the webpage\",\n",
        "\n",
        "  )\n",
        "  return {\n",
        "      \"page_url\":page_url,\n",
        "      \"detalis\":details\n",
        "  }\n"
      ],
      "metadata": {
        "id": "3m3IYExMSRiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scraping_agent = Agent(\n",
        "    role=\"Web scraping agent\",\n",
        "    goal=\"To extract Details from any website\",\n",
        "    backstory=\"Agent is designed to help in looking for required values from any websites\",\n",
        "    llm=basic_llm,\n",
        "    tools=[web_scraping_tool],\n",
        "    verbose=False\n",
        ")\n",
        "scraping_task = Task(\n",
        "    description=\"\\n\".join([\n",
        "        \"The task is to extract product details from any ecommecre stroe page url\",\n",
        "        \"The task has to collect resuclt from multiple pages urls\",\n",
        "\n",
        "    ]),\n",
        "    expected_output=\"A JSON Object containing products details\",\n",
        "    output_json=AllExtractProducts,\n",
        "    output_file=os.path.join(output_dir,\"Step_3_search_results.json\"),\n",
        "    agent=scraping_agent\n",
        ")"
      ],
      "metadata": {
        "id": "nOtXACurQz1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the AI Crew"
      ],
      "metadata": {
        "id": "9eexacT8GwD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Yazeed_crew= Crew(\n",
        "    agents=[\n",
        "        search_queries_recommendation_agent,\n",
        "        search_angine_agent,\n",
        "        scraping_agent,\n",
        "\n",
        "    ],\n",
        "    tasks=[\n",
        "        search_queries_recommendation_task,\n",
        "        search_engine_taks,\n",
        "        scraping_task,\n",
        "    ],\n",
        "    process=Process.sequential\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuLuOsoX-fJT",
        "outputId": "f206c480-5939-4fef-b39a-48cda04931cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Yazeed_crew.kickoff(\n",
        "    inputs={\n",
        "        \"product_name\":\"Caffee machine for the office\",\n",
        "        \"websites_list\":[\"www.amazon.com\", \"www.noon.com\",\"www.jumia.com.eg\"],\n",
        "        \"country_name\": \"Jordan\",\n",
        "        \"no_keywords\": \"10\",\n",
        "        \"language\":\"Engilsh\",\n",
        "        \"score_th\": 0.10,\n",
        "        \"top_recommendations_no\": 10\n",
        "\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "Wx7jSNkfPzNg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}